<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>research_review</title>
<!-- 2017-02-20 Mon 02:35 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="AWind" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">research_review</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. Review of "Mastering the game of Go with deep neural networks and tree search"</a>
<ul>
<li><a href="#sec-1-1">1.1. Introduction</a></li>
<li><a href="#sec-1-2">1.2. Techniques used</a></li>
<li><a href="#sec-1-3">1.3. Conclusion</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Review of "Mastering the game of Go with deep neural networks and tree search"</h2>
<div class="outline-text-2" id="text-1">
</div><div id="outline-container-sec-1-1" class="outline-3">
<h3 id="sec-1-1"><span class="section-number-3">1.1</span> Introduction</h3>
<div class="outline-text-3" id="text-1-1">
<p>
This paper dewscribed the algorithms and strategies used to build AlphaGo compouter program which can beat humans and other AI programs. Exhaustive search for optimal move is infeasible in Go. (150 to power 250).
</p>
</div>
</div>

<div id="outline-container-sec-1-2" class="outline-3">
<h3 id="sec-1-2"><span class="section-number-3">1.2</span> Techniques used</h3>
<div class="outline-text-3" id="text-1-2">
<p>
AlphaGo uses Monte Carlo tree search (MCTS) which needs a policy to give values to different moves. Instead of using the policies which predicts the human experts move as in current systems, AlphaGo utilizes convolution neural network. These neural networks were on  on a pipeline of ML stages. First a supervised learning (SL) policy was trained on human moves. Then a reinforcement learning policy network improves the previous stage from self play.
SL policy network was 13 layer trained on 29.4 million positions from 160,000. This gave the accuracy of 57% as against the previous best of 44.4%. Larger networks gave better performance but at the cost of higher time in evaluation. A smalller network was also trained which achieved 24.2% in 2us against 3ms. Symmetries of Go wasn't exploited as it hurt the performance of large neural networks. Instead, it is used at run time.
RL policy is similar in structure to SL policy and was initialised with same weight. Games were played between this network and a randomly selected previous iteration of policy. Then weight were updated in the direction using stochastic gradients which maximises theexpected outcomes. This network won 80% of the games head to head against SL policy network.
Final stage in pipeline is reinforcement learning of value network. In this, prediction of outcome is given using a policy for a given state of boards. This network is trained on state-outcome pairs using stochastic gradient descent to minimise the mean square error. To mitigate the overfitting, an additional 30 million data of self play was used. This approached the accuracy of RL policy network but using 1500 times less computation.
Next policy and value networks are combined with MCTS.In AlphaGo, SL policy network outperformed RL policy network but value network trained from RL policy was more accurate.
Evaluating policy and value networks require lots of computations than traditional search heuristics. Final version of AlphaGo uses 40 search threads, 48 CPUs, and 8 Gpus in asynchronous multi-threaded which executes simulation in CPUS and networks in GPUs, The distributed AlphaGo uses 40 search threads, 1,202 CPUs and 176 Gpus.
</p>
</div>
</div>
<div id="outline-container-sec-1-3" class="outline-3">
<h3 id="sec-1-3"><span class="section-number-3">1.3</span> Conclusion</h3>
<div class="outline-text-3" id="text-1-3">
<ul class="org-ul">
<li>AlphaGo 494 out of 495 games (99.8%) against other Go AI programs.
</li>
<li>Asynchronous single machine AlphaGo won 77%, 86%, and 99% of handicap games against Crazy Stone, Zen and Pachi with 4 free moves.
</li>
<li>Distributed AlphaGo won 100% of it's games and 77% against the single machine AlphaGo.
</li>
<li>Performance of AlphaGo with only value networks and only rollouts was also tested.
</li>
<li>Only value networks won against all other Go programs.
</li>
<li>Mixed evaluation of value networks and rollouts performed the best.
</li>
<li>AlphaGo beat European Champion Fan Hui 5-0.
</li>
<li>During the match against Fan Hui, AlphaGO searched thousands of times fewer positions than the Deep Blue against Kasparov.
</li>
<li>Also evaluation functions in AlphaGo aren't hardcrafted like in DeepBlue but trained through supervised learning and reinforcement learning.
</li>
</ul>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Khurram Beigh</p>
<p class="date">Created: 2017-02-20 Mon 02:35</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 25.1.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
